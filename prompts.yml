kriya_extraction_prompt: |
  Extract verbs and semantic roles.
  
  Roles:
  - KARTA = who does the action (STRING)
  - KARMA = what is acted upon (STRING)
  - SAMPRADANA = who receives (STRING)
  - KARANA = tool used (STRING)
  
  CRITICAL: All role values MUST be strings, NEVER arrays or objects.
  
  Format:
  {"extractions":[{"verb":"action","karakas":{"KARTA":"agent","KARMA":"object"}}]}
  
  Examples:
  
  Input: "John gave Mary a book."
  Output: {"extractions":[{"verb":"gave","karakas":{"KARTA":"John","KARMA":"book","SAMPRADANA":"Mary"}}]}
  
  Input: "Dr. Smith and Prof. Lee reviewed the data."
  Output: {"extractions":[{"verb":"reviewed","karakas":{"KARTA":"Dr. Smith and Prof. Lee","KARMA":"data"}}]}
  
  WRONG: {"KARTA":["Dr. Smith and Prof. Lee"]} - NO ARRAYS!
  RIGHT: {"KARTA":"Dr. Smith and Prof. Lee"} - STRING!

kriya_extraction_feedback_prompt: |
  Previous attempt failed: {feedback}
  
  Fix these issues and generate a NEW extraction:
  
  1. Extract ALL verbs (if multiple actions exist)
  2. KARTA = agent/doer (who does it)
  3. KARMA = patient/object (what is acted upon)
  4. Keep compound agents together ("X and Y" as one KARTA)
  5. Don't hallucinate - only extract what's in the text
  6. Return valid JSON with extractions array
  
  Common mistakes to avoid:
  - Swapping agent and patient
  - Splitting compound agents
  - Adding entities not in text
  - Invalid JSON syntax

kriya_scoring_prompt: |
  Score this semantic role extraction from 1-100.
  
  Check:
  1. Verb correct? (20 pts)
  2. KARTA (agent) correct? (20 pts)
  3. KARMA (patient) correct? (20 pts)
  4. Other roles correct? (20 pts)
  5. JSON valid? (10 pts)
  6. Nothing hallucinated? (10 pts)
  
  Common errors:
  - Agent labeled as patient
  - Missing compound agents ("X and Y")
  - Wrong verb tense
  - Hallucinated entities
  
  Return JSON:
  {"score":85,"reasoning":"Verb correct, KARTA correct, but KARMA missing"}
  
  Be strict. Deduct 20 points per major error.

kriya_verification_prompt: |
  Verify semantic role extractions and pick the BEST one.
  
  Input:
  - original_text: source sentence
  - candidates: list of extractions
  
  Each extraction has:
  - verb: the action
  - karakas: semantic roles (KARTA=agent, KARMA=patient, etc.)
  
  Verify:
  1. Verb matches the action in original_text
  2. KARTA (agent) appears in original_text - check the actual words
  3. KARMA (patient) appears in original_text - check the actual words
  4. Roles are correct: KARTA does the action, KARMA receives it
  
  Example:
  original_text: "Dr. Smith and Prof. Lee reviewed the data."
  GOOD: verb="reviewed", KARTA="Dr. Smith and Prof. Lee", KARMA="data"
  BAD: verb="analyzed" (wrong verb)
  BAD: KARTA="data" (swapped roles)
  
  If multiple candidates are identical and correct, pick any one (e.g., Candidate_A).
  
  Return JSON:
  {"choice":"Candidate_A"}
  
  Only return ALL_INVALID if ALL candidates have wrong verbs or swapped roles:
  {"choice":"ALL_INVALID","reasoning":"all have wrong verb"}

query_decomposition_prompt: |
  Decompose the user query into a simple graph search plan.
  
  Return JSON:
  {"steps":[{"step_number":1,"description":"what to find","entity":"target entity or null","verb":"target action or null"}],"expected_hops":1}
  
  Examples:
  
  Query: "Who is Rama?"
  Output: {"steps":[{"step_number":1,"description":"Find entity Rama","entity":"Rama","verb":null}],"expected_hops":1}
  
  Query: "What did John do?"
  Output: {"steps":[{"step_number":1,"description":"Find actions by John","entity":"John","verb":null}],"expected_hops":1}

query_scoring_prompt: |
  Score this query plan from 1-100.
  
  Check:
  1. Has valid steps? (50 pts)
  2. Entity/verb specified? (30 pts)
  3. Valid JSON? (20 pts)
  
  Return JSON:
  {"score":85,"reasoning":"Valid plan with clear entity"}

query_verification_prompt: |
  Pick the BEST query plan.
  
  Check:
  1. Has valid steps array?
  2. Entity or verb specified?
  3. Valid JSON format?
  
  Return JSON:
  {"choice":"Candidate_A"}
  
  Or if all invalid:
  {"choice":"ALL_INVALID","reasoning":"missing steps"}

coreference_resolution_prompt: |
  You are a coreference resolution expert. Given a pronoun and surrounding context, identify what entity the pronoun refers to.
  
  Return JSON with this structure:
  {
    "referent": "<entity name>",
    "confidence": "<high|medium|low>",
    "reasoning": "<brief explanation>"
  }
  
  If unable to resolve, return {"referent": null, "confidence": "low", "reasoning": "insufficient context"}

sentence_split_prompt: |
  You are a precise sentence splitter. Your task is to split text into individual sentences.
  
  CRITICAL RULES:
  1. PRESERVE EVERY CHARACTER - Do NOT alter, add, remove, or rephrase ANY text
  2. Do NOT split on abbreviations: Dr., Prof., Mr., Mrs., Ms., Inc., Ltd., Co., U.S., U.K., Ph.D., M.D., etc.
  3. Do NOT split on numbers: $2.5, 3.14, etc.
  4. Valid sentence endings: . ! or ? followed by whitespace AND capital letter (or end of text)
  5. Return ONLY a JSON array: ["sentence 1", "sentence 2", ...]
  6. Each sentence must be EXACTLY as it appears in input (character-for-character, including spaces)
  
  OUTPUT FORMAT:
  ["First sentence here.", "Second sentence here.", "Third sentence here."]
  
  EXAMPLES:
  
  Input: "Dr. Chen left. He bought apples."
  Output: ["Dr. Chen left.", "He bought apples."]
  
  Input: "Hello! How are you? I'm fine."
  Output: ["Hello!", "How are you?", "I'm fine."]
  
  Input: "The U.S. economy grew. Prof. Lee analyzed it."
  Output: ["The U.S. economy grew.", "Prof. Lee analyzed it."]
  
  Input: "The price is $2.5 million. This is significant."
  Output: ["The price is $2.5 million.", "This is significant."]
  
  IMPORTANT: If you receive feedback about errors, focus on the specific region mentioned and ensure exact character preservation.