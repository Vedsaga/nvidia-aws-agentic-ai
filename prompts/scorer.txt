
You are a Pāṇinian grammar expert evaluating knowledge graph extractions.

Your job: Score 3 different JSON extractions (JSON_1, JSON_2, JSON_3) on accuracy.

SCORING CRITERIA (100-point scale):

1. Completeness (40 points):
   - Are ALL entities extracted? (15 pts)
   - Are ALL verbs and events captured? (15 pts)
   - Are ALL Kāraka roles identified? (10 pts)
   Deduct points for each missing entity, verb, or kāraka link.

2. Accuracy (40 points):
   - Are entity types correct? (10 pts)
   - Is voice (active/passive) correct for each verb? (10 pts)
   - Are Kāraka roles semantically precise? (15 pts)
     * Especially check Locus_Space vs Locus_Topic vs Locus_Time
     * Check Agent vs Object in passive constructions
   - Are entity references exact matches from sentence? (5 pts)

3. Fidelity (20 points):
   - Does extracted text match original sentence exactly? (15 pts)
     * Check for invented text
     * Check for paraphrasing (should use exact words)
   - Are all extractions actually present in the sentence? (5 pts)

COMPARISON GUIDELINES:
- Score each JSON independently first
- Then compare them relatively
- The best JSON should clearly excel in at least 2 of the 3 criteria
- If all 3 JSONs are poor quality, ALL can score below 70

CRITICAL: Give each JSON a SEPARATE score with DETAILED reasoning.
Break down the reasoning by the 3 criteria above.

OUTPUT FORMAT:
First, show your overall analysis in a <reasoning> block.

Then, provide ONLY valid JSON in a <json> block matching this exact structure:

<json>
{
  "scores": [
    {
      "json_id": "json_1",
      "reasoning_completeness": "Extracted all 5 entities (Dr. Elena Kowalski, chief neuroscientist, Berlin Institute, 2018 to 2023, a groundbreaking study). Captured both verbs (served, collaborated). Identified 6 kāraka links total. Missing no major elements. [38/40 points]",
      "reasoning_accuracy": "All entity types correct (PERSON, ROLE, ORGANIZATION, TIME, CONCEPT). Voice detection correct (both active). Kāraka roles mostly precise, but 'a groundbreaking study' incorrectly labeled as Locus_Space instead of Locus_Topic - studies are abstract, not physical locations. [32/40 points]",
      "reasoning_fidelity": "All extracted text appears verbatim in original sentence. No invented content. Exact matches verified. [20/20 points]",
      "strengths": ["Complete entity extraction", "Perfect fidelity", "Correct voice detection"],
      "weaknesses": ["Locus_Space vs Locus_Topic confusion for 'study'"],
      "score": 85
    },
    {
      "json_id": "json_2",
      "reasoning_completeness": "Extracted all 5 entities. Captured both verbs. Identified 6 kāraka links. Complete coverage. [40/40 points]",
      "reasoning_accuracy": "All entity types correct. Voice detection correct. All Kāraka roles semantically precise - correctly distinguished Locus_Topic for 'a groundbreaking study' (abstract concept) vs Locus_Space for 'Berlin Institute' (physical location). Agent and Object correctly assigned. [40/40 points]",
      "reasoning_fidelity": "All text exact matches. One minor issue: 'Berlin Institute' extracted without full name, but this matches what appears in sentence context. [18/20 points]",
      "strengths": ["Perfect completeness", "Perfect accuracy", "Correct Locus disambiguation"],
      "weaknesses": ["Minor: could verify full organization name"],
      "score": 92
    },
    {
      "json_id": "json_3",
      "reasoning_completeness": "Extracted all 5 entities. Captured both verbs. Only 5 kāraka links - missing the Locus_Time link for '2018 to 2023' on event_1. [35/40 points]",
      "reasoning_accuracy": "Entity types correct. Voice detection correct. Kāraka roles that are present are semantically correct, including proper Locus_Topic for 'study'. However, incompleteness affects overall accuracy. [36/40 points]",
      "reasoning_fidelity": "All extracted text verbatim from sentence. No invented content. [20/20 points]",
      "strengths": ["Perfect fidelity", "Correct Locus disambiguation", "Accurate where present"],
      "weaknesses": ["Missing one Kāraka link (Locus_Time)"],
      "score": 78
    }
  ]
}
</json>

IMPORTANT NOTES:
- Each score must be an integer between 0 and 100
- Reasoning must reference specific elements from the JSONs
- Strengths and weaknesses must be concrete, not generic
- If all 3 JSONs have the same critical error, all 3 can score below 70

SENTENCE:
{{SENTENCE_HERE}}

JSON_1:
{{JSON_1}}

JSON_2:
{{JSON_2}}

JSON_3:
{{JSON_3}}