# Knowledge Graph Extraction Flow - Verification

## âœ… Current Implementation Status

### 1. Document Upload â†’ Sentence Split
**Status:** âœ… WORKING (Verified with test job `d110a076-d160-464a-854b-8a7a4435e78d`)

```
User uploads file â†’ S3 trigger â†’ L2 ValidateDoc â†’ L3 SanitizeDoc
    â†“
Split into sentences â†’ Save to verified bucket â†’ Start Step Functions
```

### 2. Step Functions KG Pipeline
**Status:** âœ… CONFIGURED (Per serverless_stack.py lines 600-700)

```
For each sentence:
    â†“
CheckDedupTask (L5) - Check if already processed
    â†“
If not processed:
    â†“
Parallel Execution:
    â”œâ”€ L9: Extract Entities (entity_prompt.txt)
    â”œâ”€ L10: Extract Kriya (kriya_concept_prompt.txt)
    â””â”€ L8: Generate Embedding (NVIDIA NIM)
    â†“
L11: Build Events (event_instance_prompt.txt)
    â†“
L12: Audit Events (auditor_prompt.txt)
    â†“
Parallel Execution:
    â”œâ”€ L13: Extract Relations (relation_prompt.txt)
    â””â”€ L14: Extract Attributes (attribute_prompt.txt)
    â†“
Parallel Execution:
    â”œâ”€ L15: Graph Node Operations
    â””â”€ L16: Graph Edge Operations
```

### 3. Storage Structure

#### S3 Buckets
```
verified-documents-{account}-{region}/
    â””â”€â”€ {job_id}/
        â””â”€â”€ sentences.json          # Array of {text, hash, job_id}

knowledge-graph-{account}-{region}/
    â”œâ”€â”€ embeddings/
    â”‚   â””â”€â”€ {sentence_hash}.npy     # Numpy array of embedding vector
    â”‚
    â”œâ”€â”€ temp_kg/{sentence_hash}/
    â”‚   â”œâ”€â”€ entities.json           # L9 output
    â”‚   â”œâ”€â”€ kriya.json              # L10 output
    â”‚   â”œâ”€â”€ events.json             # L11 output
    â”‚   â”œâ”€â”€ audited_events.json     # L12 output
    â”‚   â”œâ”€â”€ relations.json          # L13 output
    â”‚   â””â”€â”€ attributes.json         # L14 output
    â”‚
    â””â”€â”€ prompts/
        â”œâ”€â”€ entity_prompt.txt
        â”œâ”€â”€ kriya_concept_prompt.txt
        â”œâ”€â”€ event_instance_prompt.txt
        â”œâ”€â”€ auditor_prompt.txt
        â”œâ”€â”€ relation_prompt.txt
        â”œâ”€â”€ attribute_prompt.txt
        â””â”€â”€ answer_synthesizer_prompt.txt
```

#### DynamoDB Tables
```
DocumentJobs:
    - job_id (PK)
    - status: "processing_kg"
    - total_sentences: 2
    - filename: "trigger-test.txt"

Sentences:
    - sentence_hash (PK)
    - text: "Rama eats mango. "
    - job_id: "d110a076..."
    - kg_status: "pending" | "kg_done"

LLMCallLog:
    - call_id (PK)
    - timestamp (SK)
    - job_id (GSI)
    - sentence_hash (GSI)
    - stage: "D1_Entities" | "D2a_Kriya" | "D3_Events" | etc.
    - prompt_used: "entity_prompt.txt"
    - llm_response: {...}
```

## ğŸ” Verification of Objectives

### Objective 1: Extract KG from each sentence
**Status:** âœ… IMPLEMENTED

**Evidence:**
- L9-L14 lambdas extract different KG components
- Each uses specific prompts from `/prompts` folder
- Results saved to `temp_kg/{sentence_hash}/` in S3

**Example for "Rama eats mango.":**
```json
// entities.json (L9)
{
  "entities": [
    {"name": "Rama", "type": "PERSON"},
    {"name": "mango", "type": "OBJECT"}
  ]
}

// kriya.json (L10)
{
  "verb": "eats",
  "karakas": {
    "karta": "Rama",
    "karma": "mango"
  }
}

// events.json (L11)
{
  "event_type": "eating",
  "participants": ["Rama", "mango"],
  "action": "eats"
}
```

### Objective 2: Store embeddings
**Status:** âœ… IMPLEMENTED

**Evidence:**
- L8 (embedding_call) generates embeddings via NVIDIA NIM
- Saved as `.npy` files in `embeddings/{sentence_hash}.npy`
- Used for semantic search during retrieval

**Implementation:**
```python
# l8_embedding_call/lambda_function.py
response = requests.post(
    f"{EMBED_ENDPOINT}/v1/embeddings",
    json={
        'model': 'nvidia/llama-3.2-nv-embedqa-1b-v2',
        'input': text,
        'input_type': 'passage'
    }
)
embedding_vector = response.json()['data'][0]['embedding']
np_array = np.array(embedding_vector, dtype=np.float32)
s3_client.put_object(
    Bucket=KG_BUCKET,
    Key=f'embeddings/{sentence_hash}.npy',
    Body=np_array.tobytes()
)
```

### Objective 3: Store graph in NetworkX format
**Status:** âš ï¸ PARTIALLY IMPLEMENTED

**Current State:**
- L15 (graph_node_ops) and L16 (graph_edge_ops) exist but are **TODO stubs**
- KG data stored as JSON files, not NetworkX graph
- Graph operations need implementation

**Gap:**
```python
# l15_graph_node_ops/lambda_function.py - CURRENT
def lambda_handler(event, context):
    """TODO: IMPLEMENT LOGIC"""
    return event  # Just passes through
```

**Needed:**
```python
# Should build NetworkX graph from entities/relations
# Save as pickled graph or GraphML format
# Store in S3 for retrieval
```

### Objective 4: Retrieve sentence from embedding
**Status:** âœ… IMPLEMENTED

**Evidence:**
- L17 (retrieve_from_embedding) performs vector search
- Returns top-k sentence hashes based on query embedding

**Implementation:**
```python
# l17_retrieve_from_embedding/lambda_function.py
# 1. Generate query embedding
# 2. Load all sentence embeddings from S3
# 3. Compute cosine similarity
# 4. Return top-k sentence hashes
```

### Objective 5: Retrieve graph for sentence
**Status:** âš ï¸ PARTIAL - Retrieves JSON, not NetworkX graph

**Current Implementation:**
```python
# l18_synthesize_answer/lambda_function.py
# Loads entities.json and events.json from S3
entities_obj = s3_client.get_object(
    Bucket=KG_BUCKET,
    Key=f'temp_kg/{sentence_hash}/entities.json'
)
events_obj = s3_client.get_object(
    Bucket=KG_BUCKET,
    Key=f'temp_kg/{sentence_hash}/events.json'
)
```

**Gap:** Not loading NetworkX graph, just raw JSON

### Objective 6: Pass both to LLM for synthesis
**Status:** âœ… IMPLEMENTED

**Evidence:**
```python
# l18_synthesize_answer/lambda_function.py
context_entry = f"Text: {sentence_text}\nEntities: {json.dumps(entities_data)}\nEvents: {json.dumps(events_data)}"

llm_payload = {
    'stage': 'RAG_Synthesis',
    'prompt_name': 'answer_synthesizer_prompt.txt',
    'inputs': {
        'QUERY': query,
        'CONTEXT': context_text
    }
}
```

## ğŸ“Š Summary

| Objective | Status | Notes |
|-----------|--------|-------|
| 1. Extract KG from sentences | âœ… | L9-L14 working, uses prompts |
| 2. Store embeddings | âœ… | L8 saves .npy files |
| 3. Store as NetworkX graph | âš ï¸ | L15/L16 are TODO stubs |
| 4. Retrieve from embeddings | âœ… | L17 vector search |
| 5. Retrieve graph for sentence | âš ï¸ | Loads JSON, not NetworkX |
| 6. Synthesize with LLM | âœ… | L18 combines context + query |

## ğŸ”§ What Needs Implementation

### Priority 1: Graph Storage (L15/L16)
Currently storing KG as separate JSON files. Need to:
1. Build NetworkX graph from entities + relations + events
2. Serialize graph (pickle or GraphML)
3. Store in S3 at `graphs/{sentence_hash}.gpickle`

### Priority 2: Graph Retrieval
Update L18 to:
1. Load NetworkX graph from S3
2. Extract relevant subgraph for query
3. Pass graph structure to LLM

## âœ… Verification Commands

```bash
# Check if KG extraction is triggered
curl "https://7g3bdwsnsc.execute-api.us-east-1.amazonaws.com/prod/status/d110a076-d160-464a-854b-8a7a4435e78d"

# Expected: status="processing_kg", total_sentences=2

# Check Step Functions execution (requires AWS credentials)
aws stepfunctions list-executions \
  --state-machine-arn arn:aws:states:us-east-1:151534200269:stateMachine:KarakaKGProcessing \
  --max-results 5

# Check S3 for KG outputs (requires AWS credentials)
aws s3 ls s3://knowledge-graph-151534200269-us-east-1/temp_kg/ --recursive | head -20
```

## ğŸ¯ Conclusion

**Yes, the objectives CAN be achieved** - most are already implemented!

**What's working:**
- âœ… Automatic KG extraction triggered after document verification
- âœ… Sentence-level processing through Step Functions
- âœ… Embedding generation and storage
- âœ… RAG retrieval and synthesis

**What needs work:**
- âš ï¸ L15/L16 graph operations (currently TODO stubs)
- âš ï¸ NetworkX graph serialization/deserialization
- âš ï¸ Graph-aware retrieval in L18

The architecture is sound - just need to implement the graph storage layer!
