{
  "kriya_extraction_prompt": "You are a semantic role labeling expert specializing in Pāṇinian kāraka analysis. Extract ALL Kriyās (verbs/actions) and their kārakas from the given sentence.\n\nIMPORTANT: \n- A sentence may contain MULTIPLE actions. Extract each one separately.\n- For ADHIKARANA kāraka, distinguish between:\n  - ADHIKARANA_SPATIAL: Physical location (e.g., 'in the forest', 'at the palace')\n  - ADHIKARANA_TEMPORAL: Time-based location (e.g., 'in the morning', 'during the war')\n- Identify coreferences (pronouns and their likely referents) ONLY if the referent appears in the SAME sentence.\n\nReturn JSON with this exact structure:\n{\n  \"extractions\": [\n    {\n      \"verb\": \"<action verb>\",\n      \"karakas\": {\n        \"KARTA\": \"<agent/doer>\",\n        \"KARMA\": \"<patient/object>\",\n        \"KARANA\": \"<instrument>\",\n        \"SAMPRADANA\": \"<recipient>\",\n        \"APADANA\": \"<source/origin>\",\n        \"ADHIKARANA_SPATIAL\": \"<physical location>\",\n        \"ADHIKARANA_TEMPORAL\": \"<time/temporal context>\"\n      },\n      \"coreferences\": [\n        {\"pronoun\": \"<pronoun>\", \"likely_referent\": \"<entity>\", \"context\": \"<brief explanation>\"}\n      ]\n    }\n  ]\n}\n\nOmit kārakas that are not present. Include coreferences array even if empty. If multiple verbs exist, create separate extraction objects for each.",
  "kriya_extraction_feedback_prompt": "Previous extraction attempt had issues: {feedback}\n\nPlease generate a NEW extraction addressing these concerns. Ensure:\n1. All verbs/actions in the sentence are extracted (multiple if present)\n2. All kārakas are correctly identified\n3. ADHIKARANA is properly split into SPATIAL vs TEMPORAL\n4. Coreferences are identified only if referent is in the same sentence\n5. JSON structure is valid with 'extractions' array",
  "kriya_scoring_prompt": "You are an expert evaluator of semantic role labeling quality. Score the following Kriyā extraction on a scale of 1-100.\n\nEvaluation criteria:\n- Verb identification accuracy (20 points)\n- Kāraka role assignment correctness (40 points)\n- ADHIKARANA spatial/temporal distinction (15 points)\n- Coreference identification quality (15 points)\n- JSON structure validity (10 points)\n\nReturn JSON with this exact structure:\n{\n  \"reasoning\": \"<detailed explanation of score>\",\n  \"score\": <integer between 1 and 100>\n}\n\nBe strict but fair. Score must be an integer from 1 to 100.",
  "kriya_verification_prompt": "You are a semantic role labeling verifier. Check the extraction for these specific errors:\n\n1. HALLUCINATION: Entities or verbs not mentioned in the original text\n2. OMISSION: Clear verbs or kārakas missing from extraction\n3. ROLE_MISMATCH: Wrong kāraka role assigned to entity (e.g., agent labeled as patient)\n4. ADHIKARANA_ERROR: Spatial/temporal distinction incorrect\n5. MISSING_VERB: Multiple actions in sentence but only one extracted\n\nBasic validity rules:\n- Every Kriyā should have at least KARTA (agent) or KARMA (patient)\n- SAMPRADANA implies transfer/giving action\n- APADANA implies separation/source\n- KARANA and ADHIKARANA are optional but must be semantically appropriate\n\nGiven multiple candidates, select the BEST one or return 'ALL_INVALID' if none are acceptable.\n\nReturn JSON:\n{\n  \"choice\": \"<Candidate_A|Candidate_B|Candidate_C|ALL_INVALID>\",\n  \"reasoning\": \"<explanation>\",\n  \"errors_found\": [\"<list of specific errors if any>\"]\n}",
  "query_decomposition_prompt": "You are a query planning expert for knowledge graph traversal. Decompose the user query into a multi-hop graph traversal plan.\n\nThe graph has:\n- Node types: Kriyā (actions), Entity (agents/objects), Document (source text)\n- Edge types: HAS_KARTĀ, HAS_KARMA, USES_KARANA, TARGETS_SAMPRADĀNA, FROM_APĀDĀNA, LOCATED_IN, OCCURS_AT, IS_SAME_AS, CAUSES, CITED_IN\n\nReturn JSON with this structure:\n{\n  \"steps\": [\n    {\n      \"step_number\": 1,\n      \"description\": \"<what to find>\",\n      \"verb\": \"<target verb or null>\",\n      \"karakas\": {\n        \"KARTA\": \"<entity constraint or null>\",\n        \"KARMA\": \"<entity constraint or null>\"\n      },\n      \"follow_causes\": <true|false>,\n      \"follow_same_as\": <true|false>\n    }\n  ],\n  \"expected_hops\": <integer>,\n  \"reasoning\": \"<explanation of plan>\"\n}\n\nEach step should be executable as a graph traversal operation.",
  "query_scoring_prompt": "You are an expert evaluator of query execution plans. Score the following query plan on a scale of 1-100.\n\nEvaluation criteria:\n- Query understanding accuracy (25 points)\n- Graph traversal logic correctness (35 points)\n- Multi-hop reasoning completeness (20 points)\n- Executability (can it actually run on the graph?) (20 points)\n\nReturn JSON with this exact structure:\n{\n  \"reasoning\": \"<detailed explanation of score>\",\n  \"score\": <integer between 1 and 100>\n}\n\nBe strict. Score must be an integer from 1 to 100.",
  "query_verification_prompt": "You are a query plan verifier. Check if the query plan is logically sound and executable on a knowledge graph.\n\nVerify:\n1. Each step has clear graph traversal operations\n2. Edge types used are valid (HAS_KARTĀ, HAS_KARMA, CAUSES, etc.)\n3. Multi-hop logic makes sense for the question\n4. Plan doesn't have circular dependencies\n5. Expected result type matches question (yes/no, entity, narrative, etc.)\n\nGiven multiple candidate plans, select the BEST one or return 'ALL_INVALID' if none are executable.\n\nReturn JSON:\n{\n  \"choice\": \"<Candidate_A|Candidate_B|Candidate_C|ALL_INVALID>\",\n  \"reasoning\": \"<explanation>\",\n  \"issues\": [\"<list of problems if any>\"]\n}",
  "coreference_resolution_prompt": "You are a coreference resolution expert. Given a pronoun and surrounding context, identify what entity the pronoun refers to.\n\nReturn JSON with this structure:\n{\n  \"referent\": \"<entity name>\",\n  \"confidence\": \"<high|medium|low>\",\n  \"reasoning\": \"<brief explanation>\"\n}\n\nIf unable to resolve, return {\"referent\": null, \"confidence\": \"low\", \"reasoning\": \"insufficient context\"}",
  "sentence_split_prompt": "You are a precise text-processing expert.\nYour task is to split the given English text into a list of complete, grammatically correct sentences.\n\n### Rules\n- Preserve the original text exactly: do **not** add, remove, or alter any words, punctuation, or capitalization.\n- Handle abbreviations correctly (e.g., Dr., Prof., Inc., U.S.A., etc.).\n- Handle decimals and measurements correctly (e.g., $2.5 million, 3.14, 1.5 lbs.) — do not split on periods in numbers.\n- Do not split inside names, titles, or abbreviations.\n- Each output item must be one complete sentence ending in '.', '!', or '?'.\n- Output must include **all sentences** from the input and **only** sentences that appear verbatim in the input.\n\n### Output format\nReturn **only** a valid JSON array of strings.\nDo not include explanations, metadata, or extra text.\n\n### Example\nInput:\nDr. Chen and Ms. Lee left. They bought 1.5 lbs. of apples.\n\nOutput:\n[\n  \"Dr. Chen and Ms. Lee left.\",\n  \"They bought 1.5 lbs. of apples.\"\n]\n\n### Text to process\n{{ text }}"
}